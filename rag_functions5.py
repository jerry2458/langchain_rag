import os
import re
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.schema import HumanMessage

# âœ… LaTeX ìˆ˜ì‹ì„ MathJax-friendly HTMLë¡œ ë³€í™˜
def convert_latex_to_mathjax(text):
    """
    LaTeX ìˆ˜ì‹ì„ HTMLì—ì„œ MathJaxë¡œ ë Œë”ë§ ê°€ëŠ¥í•˜ë„ë¡ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    """
    if not isinstance(text, str):
        return text  # ë¹ˆ ë°ì´í„° ë°©ì§€

    # âœ… LaTeX ìˆ˜ì‹ ê°ì§€í•˜ì—¬ MathJax ë³€í™˜
    latex_regex = re.compile(r'\\\((.*?)\\\)')

    def replace_latex(match):
        latex_code = match.group(1)
        return f'<span class="mathjax">\\({latex_code}\\)</span>'

    return latex_regex.sub(replace_latex, text)


# âœ… LLMì„ ì´ìš©í•´ ì¹œì ˆí•œ í•´ì„¤ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def generate_detailed_explanation(llm, question, explanation, answer, user_prompt):
    """
    ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë¬¸ì œ, í•´ì„¤, ì •ë‹µì„ ë°”íƒ•ìœ¼ë¡œ AIê°€ ì¹œì ˆí•œ í•´ì„¤ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
    """
    formatted_prompt = PromptTemplate(
        template=(
            "{user_prompt}\n\n"
            "ğŸ”¹ ë¬¸ì œ: {question}\n"
            "ğŸ”¹ ê¸°ì¡´ í•´ì„¤: {explanation}\n"
            "ğŸ”¹ ì •ë‹µ: {answer}\n\n"
            "ğŸ’¡ AIê°€ ë³€í™˜í•œ í•´ì„¤:"
        ),
        input_variables=["user_prompt", "question", "explanation", "answer"]
    )

    response = llm.generate([[HumanMessage(content=formatted_prompt)]])
    
    return response.generations[0][0].text  # âœ… ì‘ë‹µ ê°ì²´ì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
