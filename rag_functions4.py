import os
import re
import pandas as pd
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate

# âœ… OpenAI API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["deployment_name"] = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
os.environ["openai_api_base"] = os.getenv("AZURE_OPENAI_ENDPOINT")
os.environ["openai_api_version"] = "2024-05-13"
os.environ["openai_api_key"] = os.getenv("AZURE_OPENAI_API_KEY")

# âœ… (1) LaTeX ìˆ˜ì‹ì„ MathJax-friendly HTMLë¡œ ë³€í™˜
def convert_latex_to_mathjax(text):
    if not isinstance(text, str):
        return text  # ë¹ˆ ë°ì´í„°ê°€ ë“¤ì–´ì˜¬ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    
    latex_regex = re.compile(r'\\\((.*?)\\\)')  # \( ... \) í˜•íƒœ ê°ì§€
    
    def replace_latex(match):
        latex_code = match.group(1)
        return f'<span class="mathjax">\\({latex_code}\\)</span>'
    
    return latex_regex.sub(replace_latex, text)

# âœ… (2) HTML í˜•ì‹ì˜ ë¬¸ì œ ë° í•´ì„¤ ë°ì´í„° ë¡œë“œ (LaTeX ë³€í™˜ ì ìš©)
def load_html_explanation_data(file_path):
    df = pd.read_csv(file_path)  # CSVì—ì„œ HTML í˜•ì‹ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    explanations = []
    for _, row in df.iterrows():
        explanations.append({
            "question_id": row["ë¬¸í•­ì•„ì´ë””"],  # âœ… ë¬¸í•­ì•„ì´ë”” ì¶”ê°€
            "question": convert_latex_to_mathjax(row["ë¬¸ì œ"]),
            "explanation": convert_latex_to_mathjax(row["í•´ì„¤"])
        })
    return explanations

# âœ… (3) GPTë¥¼ ì´ìš©í•´ ë¬¸ì œë¥¼ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜
def refine_question(llm, question):
    prompt_template = PromptTemplate(
        template=(
           "ğŸ”¹ ë¬¸ì œ: {question}\n"
           "ğŸ’¡ ë³€í™˜ëœ ë¬¸ì œ (ì–´ë–¤ í˜•ì‹ì´ë“  ì‚¬ìš©ìê°€ ë³´ê¸° í¸í•˜ê²Œ ëª¨ë‘ ë³€í™˜í•´ì„œ ì¶œë ¥í•´ì£¼ì„¸ìš”.):"
        ),
        input_variables=["question"]
    )

    response = llm.predict(prompt_template.format(question=question))
    return convert_latex_to_mathjax(response)  # ë³€í™˜ëœ ë¬¸ì œë¥¼ ë‹¤ì‹œ MathJax-friendly HTMLë¡œ ë³€ê²½

# âœ… (4) GPTë¥¼ ì´ìš©í•´ í•´ì„¤ì„ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def refine_explanation(llm, explanation):
    prompt_template = PromptTemplate(
        template=(
             "ë‹¤ìŒ í•´ì„¤ì„ ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
             "ğŸ”¹ í•´ì„¤: {explanation}\n\n"
             "ğŸ’¡ ë³€í™˜ëœ í•´ì„¤ (ì–´ë–¤ í˜•ì‹ì´ë“  ì‚¬ìš©ìê°€ ë³´ê¸° í¸í•œ ì–‘ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.):"
        ),
        input_variables=["explanation"]
    )

    response = llm.predict(prompt_template.format(explanation=explanation))
    return convert_latex_to_mathjax(response)  # ë³€í™˜ëœ í•´ì„¤ì„ ë‹¤ì‹œ MathJax-friendly HTMLë¡œ ë³€ê²½
