import os
import re
import pandas as pd
from langchain.document_loaders import PDFPlumberLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.chat_models import ChatOpenAI
from langchain.chains.question_answering import load_qa_chain
from langchain.prompts import PromptTemplate

# OpenAI API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["TOKENIZERS_PARALLELISM"] = "false"

__import__('pysqlite3')
import sys

sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')


# âœ… (1) LaTeX ìˆ˜ì‹ì„ MathJax-friendly HTMLë¡œ ë³€í™˜
def convert_latex_to_mathjax(text):
    latex_regex = re.compile(r'\\\((.*?)\\\)')  # \( ... \) í˜•íƒœ ê°ì§€

    def replace_latex(match):
        latex_code = match.group(1)
        return f'<span class="mathjax">\\({latex_code}\\)</span>'

    return latex_regex.sub(replace_latex, str(text))


# âœ… (2) HTML í˜•ì‹ì˜ ë¬¸ì œ ë° í•´ì„¤ ë°ì´í„° ë¡œë“œ (LaTeX ë³€í™˜ ì ìš©)
def load_html_explanation_data(file_path):
    df = pd.read_csv(file_path)  # CSVì—ì„œ HTML í˜•ì‹ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    explanations = []
    for _, row in df.iterrows():
        explanations.append({
            "question": convert_latex_to_mathjax(row["ë¬¸ì œ"]),
            "explanation": convert_latex_to_mathjax(row["í•´ì„¤"])
        })
    return explanations


# âœ… (3) PDF íŒŒì¼ ë¡œë“œ ë° í…ìŠ¤íŠ¸ ë¶„í• 
def load_and_split_pdf(file_path):
    loader = PDFPlumberLoader(file_path)
    documents = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=100)
    split_docs = text_splitter.split_documents(documents)
    return split_docs


# âœ… (4) ë²¡í„° ì €ì¥ì†Œ ìƒì„± (ë¬¸ì œ í•´ì„¤ + PDF ë‹¨ì› ì €ì¥)
def create_vector_store(explanations, pdf_texts, persist_directory="chroma_db"):
    embeddings = OpenAIEmbeddings()

    # HTML ë¬¸ì œ í•´ì„¤ì„ ChromaDBì— ì¶”ê°€
    explanation_texts = [f"<b>ë¬¸ì œ:</b> {ex['question']}<br><b>í•´ì„¤:</b> {ex['explanation']}" for ex in explanations]
    explanation_store = Chroma.from_texts(explanation_texts, embeddings,
                                          persist_directory=persist_directory + "/explanations")

    # PDF ë‹¨ì›ë„ ChromaDBì— ì¶”ê°€
    pdf_store = Chroma.from_documents(pdf_texts, embeddings, persist_directory=persist_directory + "/pdfs")

    return explanation_store, pdf_store


# âœ… (5) RAG ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì²´ì¸ ìƒì„±
def create_rag_chain():
    llm = ChatOpenAI(model_name="gpt-4", temperature=0)

    prompt_template = PromptTemplate(
        template=(
            "í•™ìƒì˜ ì§ˆë¬¸ê³¼ ê¸°ì¡´ í•´ì„¤ì„ ì°¸ê³ í•˜ì—¬, ë” ì¹œì ˆí•œ í•´ì„¤ì„ ì œê³µí•©ë‹ˆë‹¤ (HTML í˜•ì‹ ì¶œë ¥):\n\n"
            "ğŸ”¹ <b>ë¬¸ì œ</b><br>{question}<br>\n"
            "ğŸ”¹ <b>ê¸°ì¡´ í•´ì„¤</b><br>{context}<br>\n"
            "ğŸ”¹ <b>ìƒˆë¡œìš´ í•´ì„¤</b><br>\n"
            "ì´ì „ í•´ì„¤ë³´ë‹¤ ë”ìš± ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\n"
            "HTMLê³¼ LaTeX ìˆ˜ì‹ì„ ìœ ì§€í•´ ì£¼ì„¸ìš”."
        ),
        input_variables=["context", "question"]
    )

    return load_qa_chain(llm, chain_type="stuff", prompt=prompt_template)

