import os
import re
import pandas as pd
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate

# âœ… OpenAI API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["deployment_name"] = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
os.environ["openai_api_base"] = os.getenv("AZURE_OPENAI_ENDPOINT")
os.environ["openai_api_version"] = "2024-05-13"
os.environ["openai_api_key"] = os.getenv("AZURE_OPENAI_API_KEY")

# âœ… (1) LaTeX ìˆ˜ì‹ì„ MathJax-friendly HTMLë¡œ ë³€í™˜
def convert_latex_to_mathjax(text):
    if not isinstance(text, str):
        return text  # ë¹ˆ ë°ì´í„°ê°€ ë“¤ì–´ì˜¬ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    
    latex_regex = re.compile(r'\\\((.*?)\\\)')  # \( ... \) í˜•íƒœ ê°ì§€
    
    def replace_latex(match):
        latex_code = match.group(1)
        return f'<span class="mathjax">\\({latex_code}\\)</span>'
    
    return latex_regex.sub(replace_latex, text)

# âœ… (2) HTML í˜•ì‹ì˜ ë¬¸ì œ ë° í•´ì„¤ ë°ì´í„° ë¡œë“œ (LaTeX ë³€í™˜ ì ìš©)
def load_html_explanation_data(file_path):
    df = pd.read_csv(file_path)  # CSVì—ì„œ HTML í˜•ì‹ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    explanations = []
    for _, row in df.iterrows():
        explanations.append({
            "question_id": row["ë¬¸í•­ì•„ì´ë””"],  # âœ… ë¬¸í•­ì•„ì´ë”” ì¶”ê°€
            "question": convert_latex_to_mathjax(row["ë¬¸ì œ"]),
            "explanation": convert_latex_to_mathjax(row["í•´ì„¤"])
        })
    return explanations

# âœ… (3) GPTë¥¼ ì´ìš©í•´ ë¬¸ì œë¥¼ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜
def refine_question(llm, question):
    prompt_template = PromptTemplate(
        template=(
           "ë‹¤ìŒ ìˆ˜í•™ ë¬¸ì œë¥¼ ì›¹ì—ì„œ ë³´ê¸° í¸í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•´ ì£¼ì„¸ìš”."
        "ìˆ˜ì‹ì„ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ê³ , í•„ìš”í•  ê²½ìš° ë‹¨ìœ„ë¥¼ ëª…í™•íˆ í‘œì‹œí•˜ì„¸ìš”."
        "html íƒœê·¸ê°€ ì½”ë“œì²˜ëŸ¼ ë³´ì´ì§€ ì•Šê³  ì‹¤ì œë¡œ ë Œë”ë§ ë˜ë„ë¡ í•´ì£¼ì„¸ìš”."
        "ë¶ˆí•„ìš”í•œ LaTeX ëª…ë ¹ì–´ëŠ” ì œê±°í•˜ê³ , MathJaxë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ì—ì„œ ì˜ ë³´ì´ë„ë¡ ë³€í™˜í•´ ì£¼ì„¸ìš”.\n\n"
        "{question}\n\n"
        "ğŸ’¡ ë³€í™˜ëœ ë¬¸ì œ (ì–´ë–¤ í˜•ì‹ì´ë“  ì‚¬ìš©ìê°€ ë³´ê¸° í¸í•œ ì–‘ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.):"
        ),
        input_variables=["question"]
    )

    response = llm.predict(prompt_template.format(question=question))
    return convert_latex_to_mathjax(response)  # ë³€í™˜ëœ ë¬¸ì œë¥¼ ë‹¤ì‹œ MathJax-friendly HTMLë¡œ ë³€ê²½

# âœ… (4) GPTë¥¼ ì´ìš©í•´ í•´ì„¤ì„ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def refine_explanation(llm, explanation):
    prompt_template = PromptTemplate(
        template=(
             "ë‹¤ìŒ í•´ì„¤ì„ ì›¹ì—ì„œ ë³´ê¸° ì‰½ê²Œ ë³€í™˜í•˜ê³ , ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì¹œì ˆí•˜ê³  ìƒì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. "
        "html íƒœê·¸ê°€ ì½”ë“œì²˜ëŸ¼ ë³´ì´ì§€ ì•Šê³  ì‹¤ì œë¡œ ë Œë”ë§ ë˜ë„ë¡ í•´ì£¼ì„¸ìš”."
        "ë¶ˆí•„ìš”í•œ LaTeX ëª…ë ¹ì–´ëŠ” ì œê±°í•˜ê³ , MathJaxë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ì—ì„œ ì˜ ë³´ì´ë„ë¡ ë³€í™˜í•´ ì£¼ì„¸ìš”.\n\n"
        "{explanation}\n\n"
        "ğŸ’¡ ë³€í™˜ëœ í•´ì„¤ (ì–´ë–¤ í˜•ì‹ì´ë“  ì‚¬ìš©ìê°€ ë³´ê¸° í¸í•œ ì–‘ì‹ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.):"
        ),
        input_variables=["explanation"]
    )

    response = llm.predict(prompt_template.format(explanation=explanation))
    return convert_latex_to_mathjax(response)  # ë³€í™˜ëœ í•´ì„¤ì„ ë‹¤ì‹œ MathJax-friendly HTMLë¡œ ë³€ê²½
