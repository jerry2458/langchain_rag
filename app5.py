import streamlit as st
from rag_functions5 import generate_detailed_explanation
from langchain.chat_models import AzureChatOpenAI
import os

# âœ… Streamlit ì„¤ì •
st.title("ğŸ“˜ AI ìˆ˜í•™ ë¬¸ì œ í•´ì„¤ ë„ìš°ë¯¸")
st.write("ğŸ“¢ ë¬¸ì œ, í•´ì„¤, ì •ë‹µì„ ì…ë ¥í•˜ë©´ AIê°€ ì¹œì ˆí•œ í•´ì„¤ì„ ìƒì„±í•´ì¤ë‹ˆë‹¤.")

# âœ… ëª¨ë¸ë³„ ì„¤ì •ê°’ ì •ì˜ (ê° í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°)
model_options = {
    "GPT-4": {
        "deployment_name": os.getenv("AZURE_GPT4_DEPLOYMENT_NAME"),
        "api_version": os.getenv("AZURE_GPT4_API_VERSION"),
        "api_base": os.getenv("AZURE_GPT4_ENDPOINT"),
        "api_key": os.getenv("AZURE_GPT4_API_KEY"),
        "supports_temperature": True  # âœ… GPT-4ëŠ” temperature ì§€ì›
    },
    "GPT-o3-mini": {
        "deployment_name": os.getenv("AZURE_GPTo3_DEPLOYMENT_NAME"),  # âœ… í™˜ê²½ ë³€ìˆ˜ëª… ìˆ˜ì • (ì˜¤íƒ€ í™•ì¸ í•„ìš”)
        "api_version": os.getenv("AZURE_GPTo3_API_VERSION"),
        "api_base": os.getenv("AZURE_GPTo3_ENDPOINT"),
        "api_key": os.getenv("AZURE_GPTo3_API_KEY"),
        "supports_temperature": False  # âœ… GPT-o3-miniëŠ” temperature ë¯¸ì§€ì›
    }
}

# âœ… ëª¨ë¸ ì„ íƒ UI
st.sidebar.header("âš™ï¸ ëª¨ë¸ ì„¤ì •")
selected_model = st.sidebar.radio("ëª¨ë¸ ì„ íƒ", list(model_options.keys()))

# âœ… ì„ íƒí•œ ëª¨ë¸ì˜ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
selected_settings = model_options[selected_model]

# âœ… ì‚¬ìš©ì ì…ë ¥ì°½ ìƒì„± (ë¬¸ì œ, í•´ì„¤, ì •ë‹µ ì…ë ¥)
st.header("ğŸ“ ë¬¸ì œ ì…ë ¥")
question_input = st.text_area("ë¬¸ì œ ì…ë ¥", "ì´ê³³ì— ë¬¸ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
solution_input = st.text_area("ê¸°ì¡´ í•´ì„¤ ì…ë ¥", "ì´ê³³ì— ê¸°ì¡´ í•´ì„¤ì„ ì…ë ¥í•˜ì„¸ìš”.")
answer_input = st.text_input("ì •ë‹µ ì…ë ¥", "ì´ê³³ì— ì •ë‹µì„ ì…ë ¥í•˜ì„¸ìš”.")

# âœ… ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìˆ˜ì • ê°€ëŠ¥
st.sidebar.header("ğŸ“ í”„ë¡¬í”„íŠ¸ ì„¤ì •")
default_prompt = (
    "ë¬¸ì œ, í•´ì„¤, ì •ë‹µì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ í•´ì„¤ì„ ì‘ì„±í•˜ì„¸ìš”.\n"
    "ì„¤ëª…ì€ ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì¹œì ˆí•˜ê³  ìì„¸í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
    "ìˆ˜ì‹ì€ LaTeX í˜•ì‹ìœ¼ë¡œ ìœ ì§€í•˜ê³ , HTML í¬ë§·ì„ ì‚¬ìš©í•´ ê°€ë…ì„±ì„ ë†’ì—¬ì£¼ì„¸ìš”.\n"
)
user_prompt = st.sidebar.text_area("í”„ë¡¬í”„íŠ¸ ìˆ˜ì •", default_prompt, height=150)

# âœ… LLM ëª¨ë¸ ì„¤ì • (GPT-o3-miniëŠ” temperature=Noneì„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •)
if selected_settings["supports_temperature"]:
    llm = AzureChatOpenAI(
        deployment_name=selected_settings["deployment_name"],
        openai_api_version=selected_settings["api_version"],
        openai_api_base=selected_settings["api_base"],
        openai_api_key=selected_settings["api_key"],
        temperature=0.5  # âœ… GPT-4ëŠ” temperature ì‚¬ìš© ê°€ëŠ¥
    )
else:
    llm = AzureChatOpenAI(
        deployment_name=selected_settings["deployment_name"],
        openai_api_version=selected_settings["api_version"],
        openai_api_base=selected_settings["api_base"],
        openai_api_key=selected_settings["api_key"]
    )

# âœ… ë³€í™˜ ì‹¤í–‰ ë²„íŠ¼
if st.button("ğŸ”„ í•´ì„¤ ë³€í™˜ ì‹¤í–‰"):
    with st.spinner("ğŸ” AIê°€ ì¹œì ˆí•œ í•´ì„¤ì„ ìƒì„± ì¤‘..."):
        transformed_solution = generate_detailed_explanation(
            llm, question_input, solution_input, answer_input, user_prompt
        )

    # âœ… ê²°ê³¼ ì¶œë ¥
    st.header("âœ¨ ë³€í™˜ëœ ì¹œì ˆí•œ í•´ì„¤")
    st.markdown(transformed_solution, unsafe_allow_html=True)
